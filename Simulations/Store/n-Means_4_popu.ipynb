{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8EamewvRhiV"
      },
      "source": [
        "# Dpi Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5lAzzJ8sZy9Z"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 100 # 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from package_sampling.sampling import up_tille, up_brewer, up_systematic, up_max_entropy\n",
        "from package_sampling.utils import inclusion_probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/divar/projects/graphical-sampling\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/home/divar/projects/graphical-sampling')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaeYeRJUkg0Z"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo13_-M0RaP9"
      },
      "source": [
        "### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRKCwND9N8_J",
        "outputId": "4cce13ce-f942-4370-81ee-2887d316912e"
      },
      "outputs": [],
      "source": [
        "# !pip install -q git+https://github.com/mehdimhb/geometric-sampling@dev\n",
        "# !pip install git+https://github.com/mehdimhb/geometric-sampling@legacy-measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60DuP82jaME",
        "outputId": "377e9528-0f57-40d4-9b1b-591352e20fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
            "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y r-base\n",
        "#!pip install -q rpy2 tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rpy2.robjects.packages import importr\n",
        "\n",
        "import numpy as np\n",
        "from rpy2.robjects import numpy2ri, default_converter, globalenv\n",
        "from rpy2.robjects.conversion import localconverter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dvCqCmwnjuHn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rpy2.ipython extension is already loaded. To reload it, use:\n",
            "  %reload_ext rpy2.ipython\n"
          ]
        }
      ],
      "source": [
        "%load_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEcbxvujRdPr"
      },
      "source": [
        "### R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge6aoQ8fkl0n",
        "outputId": "19ad56b9-83da-49e2-a37a-de58d4bdcdd1"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "\n",
        "#library(spcosa)\n",
        "#ibrary(spsurvey)\n",
        "if(!require(WaveSampling)){\n",
        "    install.packages(\"WaveSampling\")\n",
        "    library(WaveSampling)\n",
        "}\n",
        "if(!require(sampling)){\n",
        "    install.packages(\"sampling\")\n",
        "    library(sampling)\n",
        "}\n",
        "if(!require(BalancedSampling)){\n",
        "    install.packages(\"BalancedSampling\")\n",
        "    library(BalancedSampling)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNZsi2g5mC6N"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7jjvs1ctOBa3"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "from rpy2.robjects import r, numpy2ri\n",
        "import rpy2.robjects as ro\n",
        "from matplotlib import pyplot as plt\n",
        "from itertools import combinations\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "import geometric_sampling as gs\n",
        "from tqdm import tqdm\n",
        "from tqdm.contrib import tenumerate\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#numpy2ri.activate()\n",
        "\n",
        "rng = gs.random.rng()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUVL883DmG1Z"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "autumn_cmap = plt.get_cmap('autumn')\n",
        "plasma_cmap = plt.get_cmap('plasma')\n",
        "\n",
        "def get_autumn_colors(n_clusters):\n",
        "    \"\"\"Returns n_clusters colors from the autumn colormap.\"\"\"\n",
        "    colors = autumn_cmap(np.linspace(0.15, 0.95, n_clusters))\n",
        "    return colors\n",
        "\n",
        "def get_plasma_colors(n_clusters):\n",
        "    \"\"\"Returns n_clusters colors from the plasma colormap.\"\"\"\n",
        "    colors = plasma_cmap(np.linspace(0.15, 0.95, n_clusters))\n",
        "    return colors\n",
        "\n",
        "# Example usage:\n",
        "n = 10  # Number of clusters\n",
        "n_clusters = n\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def lighten_color(color, amount=0.5):\n",
        "    import matplotlib.colors as mc\n",
        "    import colorsys\n",
        "    try:\n",
        "        c = mc.cnames[color]\n",
        "    except:\n",
        "        c = color\n",
        "    c = np.array(mc.to_rgb(c))\n",
        "    white = np.array([1, 1, 1])\n",
        "    return tuple((1 - amount) * c + amount * white)\n",
        "\n",
        "n_clusters = n\n",
        "base_colors = plt.cm.plasma(np.linspace(0, 1, n_clusters))\n",
        "light_colors = [lighten_color(col, 0.5) for col in base_colors]\n",
        "\n",
        "autumn_colors = get_autumn_colors(n_clusters)\n",
        "plasma_colors = get_plasma_colors(n_clusters)\n",
        "plasma_colors = light_colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_convex_hull(points, ax, color, alpha=0.33, edge_color=\"gray\", line_width=0.6):\n",
        "    \"\"\"Plot convex hull safely. Always returns (ax, hull or None).\"\"\"\n",
        "    if len(points) < 3:\n",
        "        return ax, None\n",
        "    try:\n",
        "        hull = ConvexHull(points)\n",
        "        polygon = Polygon(\n",
        "            points[hull.vertices],\n",
        "            closed=True,\n",
        "            facecolor=color,\n",
        "            alpha=alpha,\n",
        "            edgecolor=edge_color,\n",
        "            lw=line_width,\n",
        "            zorder=1\n",
        "        )\n",
        "        ax.add_patch(polygon)\n",
        "        return ax, hull\n",
        "    except QhullError:\n",
        "        # Can't make hull, skip\n",
        "        return ax, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyuVl1gw8_tA"
      },
      "source": [
        "# Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej46nL5U9JTF"
      },
      "source": [
        "### Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scores(coords, probs, n, N, sample_idx, split_size, density_measure=None):\n",
        "    assert len(coords) == len(probs) == N\n",
        "    assert len(sample_idx) == n\n",
        "    sample_mask = np.zeros(N, dtype=int)\n",
        "    sample_mask[sample_idx] = 1\n",
        "\n",
        "    with localconverter(default_converter + numpy2ri.converter):\n",
        "        globalenv['sample_mask'] = sample_mask\n",
        "        globalenv['sample_idx'] = sample_idx + 1  # Or int(sample_idx + 1) if it's just one value\n",
        "        globalenv['coords'] = coords\n",
        "        globalenv['probs'] = probs\n",
        "        globalenv['n'] = n\n",
        "        globalenv['N'] = N\n",
        "\n",
        "    r_code = \"\"\"\n",
        "W <- wpik(coords,probs)\n",
        "W <- W - diag(diag(W))\n",
        "diag(W) <- 0\n",
        "\n",
        "ib_value <- tryCatch({\n",
        "  IB(W, sample_mask)\n",
        "}, error = function(e) { Inf })\n",
        "\n",
        "sb_value <- tryCatch({\n",
        "  sb(probs, coords, sample_idx)\n",
        "}, error = function(e) { Inf })\n",
        "\n",
        "sblb_value <- tryCatch({\n",
        "  sblb(probs, coords, sample_idx)\n",
        "}, error = function(e) { Inf })\n",
        "\"\"\"\n",
        "    ro.r(r_code)\n",
        "    IB_value = ro.r(\"ib_value\")[0]\n",
        "    SB_value = ro.r(\"sb_value\")[0]\n",
        "    SBLB_value = ro.r(\"sblb_value\")[0]\n",
        "    if density_measure is None:\n",
        "        scaled_coords = (coords - np.min(coords, axis=0)) / np.ptp(coords, axis=0)\n",
        "        density_measure = gs.measure.Density(scaled_coords, probs, n, split_size=0.001)\n",
        "    scores_val = density_measure.score(sample_idx.reshape(1, -1))\n",
        "    return scores_val[0], IB_value, SBLB_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WbmlUyZf9QIj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import default_converter, numpy2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "\n",
        "def local_pivotal_samples(coords, probs, n, num_samples):\n",
        "    samples_idx = np.zeros((num_samples, n), dtype=int)\n",
        "    for i in range(num_samples):\n",
        "        with localconverter(default_converter + numpy2ri.converter):\n",
        "            ro.globalenv['coords'] = coords\n",
        "            ro.globalenv['probs'] = probs\n",
        "        r_code = \"\"\"\n",
        "s <- lpm(probs, coords) # Local Pivotal Method (BalancedSampling)\n",
        "\"\"\"\n",
        "        ro.r(r_code)\n",
        "        with localconverter(default_converter + numpy2ri.converter):\n",
        "            sample_idx = np.array(list(ro.r(\"s\"))) - 1\n",
        "        samples_idx[i] = sample_idx\n",
        "\n",
        "    return samples_idx\n",
        "\n",
        "def k_means_samples(coords, probs, n, num_samples, n_zones, sort_method):\n",
        "    # Placeholder, replace with your actual method if necessary\n",
        "    return gs.sampling.KMeansSpatialSamplingSimple(coords, probs, n=n, n_zones=n_zones, sort_method=sort_method, tolerance=2, split_size=0.001).sample(num_samples)\n",
        "\n",
        "def random_samples(coords, probs, n, num_samples):\n",
        "    # Placeholder, replace with your implementation if available\n",
        "    return gs.sampling.RandomSampling(coords, probs, n=n).sample(num_samples)\n",
        "\n",
        "def upmaxentropy_samples(probs, num_samples):\n",
        "    with localconverter(default_converter + numpy2ri.converter):\n",
        "        ro.globalenv['probs'] = probs\n",
        "    n = int(round(np.sum(probs)))\n",
        "\n",
        "    samples_idx = np.zeros((num_samples, n), dtype=int)\n",
        "    for i in range(num_samples):\n",
        "        r_code = \"\"\"\n",
        "mask <- UPmaxentropy(probs)\n",
        "\"\"\"\n",
        "        ro.r(r_code)\n",
        "        with localconverter(default_converter + numpy2ri.converter):\n",
        "            mask = np.array(ro.r(\"mask\"))\n",
        "        if mask.dtype != np.bool_:\n",
        "            mask = mask.astype(bool)\n",
        "        sample_idx = np.where(mask)[0]\n",
        "        samples_idx[i] = sample_idx\n",
        "\n",
        "    return samples_idx\n",
        "\n",
        "def wave_samples(coords, probs, n, num_samples):\n",
        "    with localconverter(default_converter + numpy2ri.converter):\n",
        "        ro.globalenv['coords'] = coords\n",
        "        ro.globalenv['probs'] = probs\n",
        "\n",
        "    samples_idx = np.zeros((num_samples, n), dtype=int)\n",
        "    for i in range(num_samples):\n",
        "        r_code = \"\"\"\n",
        "wave_mask <- wave(coords, probs)\n",
        "\"\"\"\n",
        "        ro.r(r_code)\n",
        "        with localconverter(default_converter + numpy2ri.converter):\n",
        "            mask = np.array(ro.r(\"wave_mask\"))\n",
        "        if mask.dtype != np.bool_:\n",
        "            mask = mask.astype(bool)\n",
        "        sample_idx = np.where(mask)[0]\n",
        "        samples_idx[i] = sample_idx\n",
        "\n",
        "    return samples_idx\n",
        "\n",
        "def spcosa_samples(coords, n, num_samples):\n",
        "    \"\"\"\n",
        "    Uses the spcosa R package for equal probability spatially balanced sampling.\n",
        "    \"\"\"\n",
        "    with localconverter(default_converter + numpy2ri.converter):\n",
        "        ro.globalenv['coords'] = coords\n",
        "    N = coords.shape[0]\n",
        "    samples_idx = np.zeros((num_samples, n), dtype=int)\n",
        "    for i in range(num_samples):\n",
        "        r_code = f\"\"\"\n",
        "library(spcosa)\n",
        "set.seed({np.random.randint(1, 1e8)})\n",
        "df <- data.frame(x = coords[,1], y = coords[,2])\n",
        "coordinates(df) <- ~x + y\n",
        "gridded(df) <- TRUE\n",
        "stratification <- stratify(df, nStrata = {n}, nTry = 50)\n",
        "samples <- spsample(stratification)\n",
        "# Extract row indices in original data\n",
        "whichrow <- as.integer(rownames(as(samples, \"data.frame\")))\n",
        "\"\"\"\n",
        "        ro.r(r_code)\n",
        "        with localconverter(default_converter + numpy2ri.converter):\n",
        "            sample_idx = np.array(ro.r(\"whichrow\")) - 1  # zero-based for Python\n",
        "        samples_idx[i] = sample_idx\n",
        "    return samples_idx\n",
        "\n",
        "def find_samples(coords, probs, n, num_samples, ep_mode=\"auto\"):\n",
        "    \"\"\"\n",
        "    Returns a dict of various sampling methods. \n",
        "    If ep_mode==\"auto\", heuristically deduce EP/UP from probs.\n",
        "    \"\"\"\n",
        "    # Determine if this is the EP case: uniform probs and sum ~ n\n",
        "    result = {\n",
        "        \"Local Pivotal\": local_pivotal_samples(coords, probs, n, num_samples),\n",
        "        \"Random\": random_samples(coords, probs, n, num_samples),\n",
        "        \"UPmaxentropy\": upmaxentropy_samples(probs, num_samples),\n",
        "        \"Wave\": wave_samples(coords, probs, n, num_samples),\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wBvI5kORuIV"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9999999999999782\n",
            "400\n",
            "name: grid_eq\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored from cffi callback <function _processevents at 0x76e11c4d28e0>:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/divar/projects/graphical-sampling/.venv/lib/python3.12/site-packages/rpy2/rinterface_lib/callbacks.py\", line 308, in _processevents\n",
            "    @ffi_proxy.callback(ffi_proxy._processevents_def,\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "folder = \"data_samples/results\"\n",
        "os.makedirs(folder, exist_ok=True)\n",
        "all_coords = []\n",
        "all_probs = []\n",
        "n = 4\n",
        "names = [\n",
        "    \"grid_eq\", \"grid_uneq\",\n",
        "    \"clust_eq\", \"clust_uneq\",\n",
        "    \"random_eq\", \"random_uneq\"\n",
        "]\n",
        "\n",
        "for name in names:\n",
        "    df = pd.read_csv(f\"data_samples/coords_probs/{name}.csv\")\n",
        "    coords = df[[\"x\", \"y\"]].values\n",
        "    probs = df[\"prob\"].values\n",
        "    with localconverter(default_converter + numpy2ri.converter):\n",
        "        globalenv['probs'] = probs\n",
        "        globalenv['n']     = n\n",
        "        # this will overwrite the R variable `probs` with the output of the function\n",
        "        r('probs <- inclusionprobabilities(probs, n)')\n",
        "        # convert it back into a NumPy array\n",
        "        new_probs = np.array(globalenv['probs'])\n",
        "\n",
        "# 4) Replace your Python variable\n",
        "    probs = new_probs\n",
        "\n",
        "\n",
        "    all_coords.append(coords)\n",
        "    all_probs.append(probs)\n",
        "print(sum(probs))\n",
        "print(len(probs))\n",
        "sample_cnt = 1000\n",
        "columns = [\"Method\", \"Density\", \"Moran\", \"Local Balance\"]\n",
        "\n",
        "for coords, probs, name in zip(all_coords, all_probs, names):\n",
        "    print('name:', name)\n",
        "    n = int(np.round(np.sum(probs)))\n",
        "    N =len(probs)\n",
        "    # Any code for one set, put here:\n",
        "    sample_methods = find_samples(coords, probs, n, sample_cnt)\n",
        "    scaled_coords = (coords - np.min(coords, axis=0)) / np.ptp(coords, axis=0)\n",
        "    density_measure = gs.measure.Density(scaled_coords, probs, n, split_size=0.001)\n",
        "    print('density_measure:', density_measure)\n",
        "    rows = np.array([\n",
        "    [method, *scores(coords, probs, n, N, s, density_measure)]\n",
        "    for method, samples in sample_methods.items()\n",
        "    if samples is not None  # <----- add this\n",
        "    for s in tqdm(samples, total=sample_cnt)\n",
        "])\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "    df = df.astype({\n",
        "        \"Density\": float,\n",
        "        \"Moran\": float,\n",
        "        \"Voronoi\": float\n",
        "    })\n",
        "    filename = os.path.join(folder, f\"final_results_{name}_n={n}.csv\")\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Saved: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwritten: data_samples/results/results_clust_eq.csv\n",
            "Overwritten: data_samples/results/results_clust_uneq.csv\n",
            "Overwritten: data_samples/results/results_grid_eq.csv\n",
            "Overwritten: data_samples/results/results_grid_uneq.csv\n",
            "Overwritten: data_samples/results/results_random_eq.csv\n",
            "Overwritten: data_samples/results/results_random_uneq.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder = \"data_samples/results\"\n",
        "names = [\n",
        "    \"clust_eq\", \"clust_uneq\",\n",
        "    \"grid_eq\", \"grid_uneq\",\n",
        "    \"random_eq\", \"random_uneq\"\n",
        "]\n",
        "\n",
        "for name in names:\n",
        "    # File paths\n",
        "    initial_result_path = os.path.join(folder, f\"initial_results_{name}.csv\")\n",
        "    result_path = os.path.join(folder, f\"results_{name}.csv\")\n",
        "\n",
        "    # Read initial results (with header)\n",
        "    initial_df = pd.read_csv(initial_result_path)\n",
        "\n",
        "    # Read simulation results (SKIP header, but use correct columns)\n",
        "    result_df = pd.read_csv(result_path, skiprows=1, names=initial_df.columns)\n",
        "\n",
        "    # Combine both, initial first, then simulation\n",
        "    combined_df = pd.concat([initial_df, result_df], ignore_index=True)\n",
        "\n",
        "    # Overwrite results file (no header duplication!)\n",
        "    combined_df.to_csv(result_path, index=False)\n",
        "    print(f\"Overwritten: {result_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Design   | Scenario   | Method        |     Density |      Moran |   Local Balance |\n",
            "|:---------|:-----------|:--------------|------------:|-----------:|----------------:|\n",
            "| grid     | equal      | Local Pivotal | -0.103637   | -0.122935  |        0.382222 |\n",
            "| grid     | equal      | Random        | -0.396706   | -0.0434621 |        0.496185 |\n",
            "| grid     | equal      | UPmaxentropy  | -0.395446   | -0.0449588 |        0.492392 |\n",
            "| grid     | equal      | cube          | -0.412348   | -0.0397319 |        0.501449 |\n",
            "| grid     | equal      | wave          |  0.0266841  | -0.197509  |        0.349212 |\n",
            "| grid     | unequal    | Local Pivotal | -0.263398   | -0.101291  |        0.735206 |\n",
            "| grid     | unequal    | Random        | -0.352008   | -0.0335465 |        8.97953  |\n",
            "| grid     | unequal    | UPmaxentropy  | -0.482192   | -0.028425  |        0.839956 |\n",
            "| grid     | unequal    | cube          | -0.339907   | -0.0389685 |       15.8776   |\n",
            "| grid     | unequal    | wave          | -0.183582   | -0.152379  |        0.637266 |\n",
            "| clust    | equal      | Local Pivotal | -0.00197206 | -0.193939  |        0.328647 |\n",
            "| clust    | equal      | Random        | -0.367769   | -0.0516444 |        0.518694 |\n",
            "| clust    | equal      | UPmaxentropy  | -0.372542   | -0.0579977 |        0.519233 |\n",
            "| clust    | equal      | cube          | -0.369932   | -0.0544931 |        0.525777 |\n",
            "| clust    | equal      | wave          |  0.030997   | -0.298926  |        0.318528 |\n",
            "| clust    | unequal    | Local Pivotal | -0.300379   | -0.10265   |        0.667751 |\n",
            "| clust    | unequal    | Random        | -0.360622   | -0.040158  |        3.14553  |\n",
            "| clust    | unequal    | UPmaxentropy  | -0.501517   | -0.031156  |        0.791094 |\n",
            "| clust    | unequal    | cube          | -0.364221   | -0.0425091 |        3.62408  |\n",
            "| clust    | unequal    | wave          | -0.25457    | -0.158003  |        0.635389 |\n",
            "| random   | equal      | Local Pivotal | -0.0955877  | -0.127521  |        0.376977 |\n",
            "| random   | equal      | Random        | -0.410568   | -0.041418  |        0.51156  |\n",
            "| random   | equal      | UPmaxentropy  | -0.405538   | -0.0414655 |        0.506246 |\n",
            "| random   | equal      | cube          | -0.408431   | -0.0418796 |        0.510282 |\n",
            "| random   | equal      | wave          |  0.0170303  | -0.208852  |        0.345447 |\n",
            "| random   | unequal    | Local Pivotal | -0.229823   | -0.104403  |        0.656337 |\n",
            "| random   | unequal    | Random        | -0.313442   | -0.0366907 |        4.56925  |\n",
            "| random   | unequal    | UPmaxentropy  | -0.453531   | -0.028696  |        0.819475 |\n",
            "| random   | unequal    | cube          | -0.318466   | -0.0332737 |        4.37207  |\n",
            "| random   | unequal    | wave          | -0.125582   | -0.155349  |        0.640479 |\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) List of file‑name stems (must match the part after \"results_meuse_\" and before \"_n=4.csv\")\n",
        "names = [\n",
        "    \"grid_eq\",   \"grid_uneq\",\n",
        "    \"clust_eq\",  \"clust_uneq\",\n",
        "    \"random_eq\", \"random_uneq\"\n",
        "]\n",
        "\n",
        "# 2) Base folder where all your CSVs live\n",
        "base_dir = \"/home/divar/projects/graphical-sampling/data_samples/results\"\n",
        "\n",
        "# 3) Read each file, compute its means, and tag scenario + design\n",
        "mean_dfs = []\n",
        "for stem in names:\n",
        "    path = f\"{base_dir}/results_{stem}.csv\"\n",
        "    df   = pd.read_csv(path)\n",
        "    df = df[~df[\"Method\"].str.contains(\"K-Means\")]\n",
        "\n",
        "    # compute means of the three indexes\n",
        "    mdf = (\n",
        "        df\n",
        "        .groupby(\"Method\")[[\"Density\",\"Moran\",\"Local Balance\"]]\n",
        "        .mean()\n",
        "        .reset_index()\n",
        "    )\n",
        "    \n",
        "    # extract scenario & design from the file‑stem\n",
        "    scenario = \"equal\"   if stem.endswith(\"_eq\")   else \"unequal\"\n",
        "    design   = stem.split(\"_\")[0]  # \"grid\", \"clust\", or \"random\"\n",
        "    \n",
        "    mdf[\"Scenario\"] = scenario\n",
        "    mdf[\"Design\"]   = design\n",
        "    \n",
        "    mean_dfs.append(mdf)\n",
        "\n",
        "# 4) Concatenate into one table\n",
        "result = pd.concat(mean_dfs, ignore_index=True)\n",
        "\n",
        "# 5) Reorder columns for clarity\n",
        "result = result[[\n",
        "    \"Design\", \"Scenario\", \"Method\",\n",
        "    \"Density\", \"Moran\", \"Local Balance\"\n",
        "]]\n",
        "\n",
        "# 6) Print as markdown (or use result.to_csv(...) / display however you like)\n",
        "print(result.to_markdown(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L8EamewvRhiV",
        "Yo13_-M0RaP9",
        "BEcbxvujRdPr",
        "eNZsi2g5mC6N",
        "ugL9lyKcmK7h",
        "uCLKd3elnAA_",
        "Gl_TYPfeL2ra",
        "2APKT0SFUP4N"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "geometric-sampling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
