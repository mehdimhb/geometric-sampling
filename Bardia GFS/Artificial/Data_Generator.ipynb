{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import numpy as np\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/divar/projects/geometric-sampling')\n",
    "import geometric_sampling\n",
    "\n",
    "import geometric_sampling as gs\n",
    "from geometric_sampling.search.astar import AStar\n",
    "from geometric_sampling.design import Design\n",
    "from geometric_sampling.criteria.var_nht import VarNHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "#install.packages(\"sampling\")\n",
    "library(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "Ppi <- function(Pi) {\n",
    "  \n",
    "  N <- length(Pi)\n",
    "  #SOME ERROR MESSAGES\n",
    "  if (N < 2) {\n",
    "    rlang::abort(\"The sampling designs should be define on a set of more than one element. (length(Pi) > 1)\")\n",
    "  }\n",
    "  \n",
    "  for (k in 1:N) {\n",
    "    if (Pi[k] >= 1 | Pi[k] <= 0) {\n",
    "      rlang::abort(\"Pi is not a vector of probabilities (0 <= p < 1)\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  if (as.integer(round( sum(Pi) , 9)) - round( sum(Pi) , 9) != 0) {\n",
    "    rlang::abort(\"The sum of the first order inclusion probabilities should be an integer\")\n",
    "  }\n",
    "  \n",
    "  \n",
    "  s <- c()\n",
    "  c <- c()\n",
    "  kr <- c()\n",
    "  alpha <-c()\n",
    "  sum <-0\n",
    "  r<-1\n",
    "  r_prev<-0\n",
    "  n_<-sum(Pi)\n",
    "  \n",
    "  for (k in 1:N) {\n",
    "    prev_sum<-sum\n",
    "    sum<-sum+Pi[k]\n",
    "    if (sum>=r)\n",
    "    {\n",
    "      kr[r] <- k\n",
    "      alpha[k] <-r-prev_sum\n",
    "      \n",
    "      int <- sqrt( (1 - Pi[k]) / (1 - alpha[k]) )\n",
    "      s[k] <- round(int, 8)\n",
    "      r_prev<-r\n",
    "      r<-r+1\n",
    "    }\n",
    "    \n",
    "    else {\n",
    "      inter <- sqrt( Pi[k] / (r_prev + 1 - prev_sum) )\n",
    "      s[k] <- round(inter, digits = 15)\n",
    "    }\n",
    "    \n",
    "    c[k] <- sqrt(1 - s[k]^2)\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # ce point n'est pas joli, mais je n'ai pas trouvÃ© l'erreur. A retravailler..\n",
    "  #print(kr)\n",
    "  if(max(kr)!=length(Pi)){\n",
    "    kr<-cbind(kr,length(Pi))\n",
    "    r<-r+1\n",
    "    r_prev<-r_prev+1}\n",
    "  #print(kr)\n",
    "  V <- matrix(0, nrow = N , ncol = r_prev)\n",
    "  V[1, 1] = 1\n",
    "  if ((r_prev-1) != 0) {\n",
    "    for (r in 1:(r_prev-1)) {\n",
    "      V[kr[r] + 1, r + 1] = 1\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  for (k in 1:(N-1)) {\n",
    "    L <- V[k, ]\n",
    "    M <- V[k + 1,]\n",
    "    V[k, ] <- s[k] * L - c[k] * M\n",
    "    V[k + 1, ] <- c[k] * L + s[k] * M\n",
    "  }\n",
    "  return(V)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Drawing_Dsd <- function(v, s = 1, B = FALSE, seed = NULL){\n",
    "  \n",
    "  \n",
    "  if (is.numeric(v)) {\n",
    "    return(.dsd_sampling_mult(v, s, B, seed))\n",
    "  }\n",
    "  else{ return(.dsd_sampling_mult_complex(v, s, B, seed))}\n",
    "}\n",
    "\n",
    "\n",
    ".dsd_sampling_mult_complex <- function(v, s, B, seed){\n",
    "  \n",
    "  if (s == 1) {\n",
    "    return(.dsd_sampling_01_B_C_complex(v, B, seed))\n",
    "  }\n",
    "  \n",
    "  else{\n",
    "    echant <- replicate(s, .dsd_sampling_01_B_C_complex(v, B, seed))\n",
    "    colnames(echant) <- paste(\"Sample\", 1:s)\n",
    "    return(echant)\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    ".dsd_sampling_mult <- function(v = NULL, s, B,seed){\n",
    "  \n",
    "  if (s == 1) {\n",
    "    return(.dsd_sampling_01_B_C(v, B, seed))\n",
    "  }\n",
    "  else{\n",
    "    echant <- replicate(s, .dsd_sampling_01_B_C(v, B, seed))\n",
    "    colnames(echant) <- paste(\"Sample\", 1:s)\n",
    "    return(echant)\n",
    "  }\n",
    "}\n",
    "\n",
    ".dsd_sampling_01_B_C_complex <- function(v, B = TRUE, seed){\n",
    "  \n",
    "  indices <- .data <- NULL\n",
    "  \n",
    "  N <- nrow(v)\n",
    "  n <- ncol(v)\n",
    "  echant <- rep(0, N)\n",
    "  \n",
    "  if (!is.null(seed)) {\n",
    "    set.seed(seed)\n",
    "  }\n",
    "  ref <- stats::runif(n)\n",
    "  \n",
    "  #Step 1: Sampling the first element\n",
    "  w <- v\n",
    "  \n",
    "  total <- 0\n",
    "  i <- 0\n",
    "  pi1 <- Re( diag( v %*% t(Conj(v)) ) )\n",
    "  \n",
    "  if (length(pi1[pi1 < 0]) != 0 | length(pi1[pi1 >= 1]) != 0) {\n",
    "    rlang::abort(\"The matrix v given as input doesn't suit to the input expected (See the functions pgd and periodic_dsd)\")\n",
    "  }\n",
    "  \n",
    "  while (total < ref[1]) {\n",
    "    i <- i + 1\n",
    "    total <- total + ( pi1[i] / n )\n",
    "  }\n",
    "  echant[i] <- 1\n",
    "  \n",
    "  M <- v[i,]\n",
    "  e1 <- M / c(Re (sqrt (t(M) %*% Conj(M)) ) )\n",
    "  \n",
    "  \n",
    "  #Step 2: Sampling the n-1 others elements\n",
    "  for (j in 1:(n-1)) {\n",
    "    \n",
    "    r <- n-j\n",
    "    inter <- v %*% Conj(e1)\n",
    "    pi1 <- pi1 - t(inter * Conj(inter))\n",
    "    pi2 <- Re( 1 / r*pi1 )\n",
    "    \n",
    "    \n",
    "    total <- 0\n",
    "    i <- 0\n",
    "    \n",
    "    while (total < ref[j+1]) {\n",
    "      i <- i + 1\n",
    "      total <- total + pi2[i]\n",
    "    }\n",
    "    echant[i] <- 1\n",
    "    \n",
    "    \n",
    "    w <- w - t( t(Conj(e1)) %*% t(w) ) %*% t(e1)\n",
    "    L <- w[i, ]\n",
    "    e1 <- L / c(Re(sqrt (t(L) %*% Conj(L) )))\n",
    "    \n",
    "  }\n",
    "  \n",
    "  if(B) {\n",
    "    return(echant)\n",
    "  }\n",
    "  else {\n",
    "    return((1:N)[echant==1])\n",
    "  }\n",
    "  \n",
    "}\n",
    ".dsd_sampling_01_B_C <- function(v = NULL, B = TRUE, seed){\n",
    "  \n",
    "  indices <- .data <- NULL\n",
    "  \n",
    "  N <- nrow(v)\n",
    "  n <- ncol(v)\n",
    "  echant <- rep(0, N)\n",
    "  \n",
    "  if (!is.null(seed)) {\n",
    "    set.seed(seed)\n",
    "  }\n",
    "  ref <- stats::runif(n)\n",
    "  \n",
    "  #First step: Sampling the first element\n",
    "  w <- v\n",
    "  \n",
    "  \n",
    "  total <- 0\n",
    "  i <- 0\n",
    "  pi1 <- diag(v  %*% t(v))\n",
    "  \n",
    "  while (total < ref[1]) {\n",
    "    i <- i + 1\n",
    "    total <- total + ( pi1[i] / n )\n",
    "  }\n",
    "  echant[i] <- 1\n",
    "  \n",
    "  \n",
    "  l <- v[i,]\n",
    "  e1 <- l / as.numeric( sqrt( t(l) %*% l ) )\n",
    "  \n",
    "  \n",
    "  #Step 2: Sampling the n-1 others elements\n",
    "  for (j in 1:(n-1)) {\n",
    "    \n",
    "    r <- n-j\n",
    "    inter <- (v %*% e1)\n",
    "    pi1 <- pi1 - t( inter * inter )\n",
    "    pi2 <- 1 / r * pi1\n",
    "    \n",
    "    \n",
    "    total <- 0\n",
    "    i <- 0\n",
    "    \n",
    "    while (total < ref[j+1]) {\n",
    "      i <- i + 1\n",
    "      total <- total + pi2[i]\n",
    "    }\n",
    "    echant[i] <- 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    w <- w - (w %*% e1) %*% t(e1)\n",
    "    L <- w[i,]\n",
    "    e1 <- L / as.numeric( sqrt( t(L) %*% L ))\n",
    "    \n",
    "  }\n",
    "  if(B) {\n",
    "    return(echant)\n",
    "  }\n",
    "  else {\n",
    "    return((1:N)[echant==1])\n",
    "  }\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "N <- 100\n",
    "n = 10\n",
    "set.seed(1983)\n",
    "mu <- 100\n",
    "b = 5\n",
    "sigma_y <- 10\n",
    "#target_rhos <- c(0.9, 0.8, 0.75)\n",
    "\n",
    "m = 2000\n",
    "balance_on_intercept = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(sampling)\n",
    "\n",
    "target_rhos <- c(0.65, 0.75, 0.85, 0.95)\n",
    "# --- generate y only once ---\n",
    "y <- rnorm(N, mu, sigma_y)\n",
    "\n",
    "# Precompute all z's\n",
    "z_list <- list()\n",
    "for (rho_z in target_rhos) {\n",
    "  sigma_zerr <- sqrt(var(y) * (1/rho_z^2 - 1))\n",
    "  z_list[[as.character(rho_z)]] <- b * (y + rnorm(N, 0, sigma_zerr))\n",
    "}\n",
    "\n",
    "# Precompute all p's\n",
    "p_list <- list()\n",
    "for (rho_p in target_rhos) {\n",
    "  sigma_perr <- sqrt(var(y) * (1/rho_p^2 - 1))\n",
    "  p_list[[as.character(rho_p)]] <- b * (y + rnorm(N, 0, sigma_perr))\n",
    "}\n",
    "\n",
    "# You now have exactly 3 z and 3 p (not 9!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.71 0.72\n",
      "[1] 0.71 0.60\n",
      "[1] 0.71 0.85\n",
      "[1] 0.71 0.96\n",
      "[1] 0.80 0.72\n",
      "[1] 0.8 0.6\n",
      "[1] 0.80 0.85\n",
      "[1] 0.80 0.96\n",
      "[1] 0.86 0.72\n",
      "[1] 0.86 0.60\n",
      "[1] 0.86 0.85\n",
      "[1] 0.86 0.96\n",
      "[1] 0.95 0.72\n",
      "[1] 0.95 0.60\n",
      "[1] 0.95 0.85\n",
      "[1] 0.95 0.96\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "vars_results <- list()\n",
    "for (rho_z in target_rhos) {\n",
    "  for (rho_p in target_rhos) {\n",
    "    z <- z_list[[as.character(rho_z)]]\n",
    "    p <- p_list[[as.character(rho_p)]]\n",
    "    pik <- inclusionprobabilities(p, n)\n",
    "\n",
    "    print(round(c(cor(y,z),cor(y,pik)),2))\n",
    "\n",
    "    label <- paste0(\"cor_zy_\", rho_z*10, \"_py_\", rho_p*10)\n",
    "    data <- data.frame(y=y, z=z, pik=pik)\n",
    "   \n",
    "    pik = data$pik\n",
    "    # Other designs variances\n",
    "    pikl_sys = UPsystematicpi2(pik)\n",
    "    pikl_max = UPmaxentropypi2(pik)\n",
    "    pikl_mid = UPmidzunopi2(pik)\n",
    "    pikl_til = UPtillepi2(pik)\n",
    "    \n",
    "    z_hat = data$z / pik\n",
    "    y_hat = data$y / pik\n",
    "    var__sys <- t(z_hat) %*% (pikl_sys - (pik %*% t(pik))) %*% z_hat\n",
    "    var__max <- t(z_hat) %*% (pikl_max - (pik %*% t(pik))) %*% z_hat\n",
    "    var__mid <- t(z_hat) %*% (pikl_mid - (pik %*% t(pik))) %*% z_hat\n",
    "    var__til <- t(z_hat) %*% (pikl_til - (pik %*% t(pik))) %*% z_hat\n",
    "    var__srs <- (N**2)*(1-n/N)*(1/n)*var(z)\n",
    "    var__sys_y <- t(y_hat) %*% (pikl_sys - (pik %*% t(pik))) %*% y_hat\n",
    "    var__max_y <- t(y_hat) %*% (pikl_max - (pik %*% t(pik))) %*% y_hat\n",
    "    var__mid_y <- t(y_hat) %*% (pikl_mid - (pik %*% t(pik))) %*% y_hat\n",
    "    var__til_y <- t(y_hat) %*% (pikl_til - (pik %*% t(pik))) %*% y_hat\n",
    "    var__srs_y <- (N**2)*(1-n/N)*(1/n)*var(y)\n",
    "    \n",
    "    # Save all variables for this scenario in a list:\n",
    "    vars_results[[label]] <- list(\n",
    "      var__sys = var__sys,\n",
    "      var__max = var__max,\n",
    "      var__mid = var__mid,\n",
    "      var__til = var__til,\n",
    "      var__srs = var__srs,\n",
    "      var__sys_y = var__sys_y,\n",
    "      var__max_y = var__max_y,\n",
    "      var__mid_y = var__mid_y,\n",
    "      var__til_y = var__til_y,\n",
    "      var__srs_y = var__srs_y\n",
    "    )\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.65 0.65\n",
      "[1] 0.65 0.75\n",
      "[1] 0.65 0.85\n",
      "[1] 0.65 0.95\n",
      "[1] 0.75 0.65\n",
      "[1] 0.75 0.75\n",
      "[1] 0.75 0.85\n",
      "[1] 0.75 0.95\n",
      "[1] 0.85 0.65\n",
      "[1] 0.85 0.75\n",
      "[1] 0.85 0.85\n",
      "[1] 0.85 0.95\n",
      "[1] 0.95 0.65\n",
      "[1] 0.95 0.75\n",
      "[1] 0.95 0.85\n",
      "[1] 0.95 0.95\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "all_data = list()\n",
    "for (rho_z in target_rhos) {\n",
    "  for (rho_p in target_rhos) {\n",
    "    print(c(rho_z,rho_p))\n",
    "    z <- z_list[[as.character(rho_z)]]\n",
    "    p <- p_list[[as.character(rho_p)]]\n",
    "\n",
    "    pik <- inclusionprobabilities(p, n)\n",
    "\n",
    "    label <- paste0(\"cor_zy_\", rho_z*10, \"_py_\", rho_p*10)\n",
    "    sort_index <- order(z / pik, decreasing = TRUE)\n",
    "    y_ <- y[sort_index]; z_ <- z[sort_index]; pik_ <- pik[sort_index]; p_ = p[sort_index]\n",
    "    N_ <- length(y_)\n",
    "    dat <- data.frame(y=y_, z=z_, pik=pik_)\n",
    "    all_data[[label]] <- dat\n",
    "    Base <- Ppi(pik_)\n",
    "    Ppi_mat <- Base %*% t(Base)\n",
    "    Dpi_inv <- diag(1 / pik_)\n",
    "    I_N <- diag(N_)\n",
    "    A <- (I_N - Ppi_mat) * Ppi_mat\n",
    "    var_ht_z <- as.numeric(t(z_) %*% Dpi_inv %*% A %*% Dpi_inv %*% z_)\n",
    "    var_ht_y <- as.numeric(t(y_) %*% Dpi_inv %*% A %*% Dpi_inv %*% y_)\n",
    "    \n",
    "    ones = rep(1, N_)\n",
    "    ht_estimates_dsd_y <- numeric(m)\n",
    "    ht_estimates_dsd_z <- numeric(m)\n",
    "    ht_estimates_cube_y <- numeric(m)\n",
    "    ht_estimates_cube_z <- numeric(m)\n",
    "    \n",
    "    for (i in 1:m) {\n",
    "      samp <- Drawing_Dsd(Base, s = n, B = TRUE)\n",
    "      sel_idx <- which(samp[, 1] == 1)\n",
    "      ht_estimates_dsd_y[i] <- sum(y_[sel_idx] / pik_[sel_idx])\n",
    "      ht_estimates_dsd_z[i] <- sum(z_[sel_idx] / pik_[sel_idx])\n",
    "      if (balance_on_intercept == 1) {\n",
    "        XX <- cbind(pik_, ones, z_)\n",
    "      } else {\n",
    "        XX <- cbind(pik_, z_)\n",
    "      }\n",
    "      cube_sample <- samplecube(XX, pik_, comment = FALSE)\n",
    "      sel_cube <- which(cube_sample == 1)\n",
    "      ht_estimates_cube_y[i] <- sum(y_[sel_cube] / pik_[sel_cube])\n",
    "      ht_estimates_cube_z[i] <- sum(z_[sel_cube] / pik_[sel_cube])\n",
    "    }\n",
    "    \n",
    "    var_cube_y  <- var(ht_estimates_cube_y)\n",
    "    var_cube_z  <- var(ht_estimates_cube_z)\n",
    "    mean_cube_y <- mean(ht_estimates_cube_y)\n",
    "    mean_cube_z <- mean(ht_estimates_cube_z)\n",
    "    var_dsd_y   <- var_ht_y\n",
    "    var_dsd_z   <- var_ht_z\n",
    "    mean_dsd_y  <- mean(ht_estimates_dsd_y)\n",
    "    mean_dsd_z  <- mean(ht_estimates_dsd_z)\n",
    "    \n",
    "    # --- Save extra ---\n",
    "    save_df <- data.frame(\n",
    "      var_ht_z = var_ht_z,\n",
    "      var_ht_y = var_ht_y,\n",
    "      var_cube_z = var_cube_z,\n",
    "      var_cube_y = var_cube_y,\n",
    "      mean_cube_y = mean_cube_y,\n",
    "      mean_cube_z = mean_cube_z,\n",
    "      mean_dsd_y = mean_dsd_y,\n",
    "      mean_dsd_z = mean_dsd_z,\n",
    "      n = n,\n",
    "      N = N_\n",
    "    )\n",
    "    write.csv(save_df, paste0(label, '_extra.csv'), row.names = FALSE)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Save these: one .csv per scenario\n",
    "for (label in names(all_data)) {\n",
    "  write.csv(all_data[[label]], paste0(label, \".csv\"), row.names=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bardia_balance_method = 'origin'\n",
    "num_new_nodes          = 30\n",
    "num_changes_lower      = 1\n",
    "num_changes_upper      = 3\n",
    "max_open_set_size      = 200000\n",
    "switch_lower           = .7\n",
    "switch_upper           = .9\n",
    "max_iterations         = 5000\n",
    "num_initial_nodes      = 3000\n",
    "initial_design_to_use  = 100\n",
    "num_top_restart_nodes  = 10\n",
    "stuck_fraction         = 0.99\n",
    "swap_iterations        = int(np.round(.7 * num_initial_nodes))  # ensure integer!\n",
    "swap_distance          = 3\n",
    "swap_units             = int(20)\n",
    "\n",
    "show_results           = 1\n",
    "random_restart_period  = 10000   # how often to inject random designs\n",
    "random_injection_count = 500     # how many random designs to inject\n",
    "prune_fraction         = .9\n",
    "var_percent_exected    = .1  # how much of the variance to expect in the best design\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = f\"config_{bardia_balance_method}.csv\"\n",
    "\n",
    "config = {\n",
    "    'bardia_balance_method': bardia_balance_method,\n",
    "    'num_new_nodes': num_new_nodes,\n",
    "    'num_changes_lower': num_changes_lower,\n",
    "    'num_changes_upper': num_changes_upper,\n",
    "    'max_open_set_size': max_open_set_size,\n",
    "    'switch_lower': switch_lower,\n",
    "    'switch_upper': switch_upper,\n",
    "    'max_iterations': max_iterations,\n",
    "    'num_initial_nodes': num_initial_nodes,\n",
    "    'initial_design_to_use': initial_design_to_use,\n",
    "    'num_top_restart_nodes': num_top_restart_nodes,\n",
    "    'stuck_fraction': stuck_fraction,\n",
    "    'swap_iterations': swap_iterations,\n",
    "    'swap_distance': swap_distance,\n",
    "    'swap_units': swap_units,\n",
    "    'show_results': show_results,\n",
    "    'random_restart_period': random_restart_period,\n",
    "    'random_injection_count': random_injection_count,\n",
    "    'prune_fraction': prune_fraction,\n",
    "    'var_percent_exected': var_percent_exected\n",
    "}\n",
    "\n",
    "with open(filename, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(config.keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerow(config)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wyG16iiGtd0m",
    "my_SDJhHPJ-R",
    "pY7PKxMkGyff",
    "1u7yLG2ptj5X",
    "7qPEqapj2T55",
    "lue3vjX9Fmwc",
    "fvRhEECaEkme",
    "SUCF-zH5toBk",
    "mBHTMr4XA3q_",
    "y6PfxqDzBwvJ",
    "n_HxQOXbHsJx",
    "9xht0qIjkXBR",
    "733GZrJqwnvr",
    "kAUtLvaHwwAy"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
